{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn.model_selection as selection\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.linear_model as linear\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn import tree\n",
    "\n",
    "# import some data to play with\n",
    "# This is a mutli-class classification problem\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipelines\n",
    "\n",
    "In this notebook, we will explore the different facilities that sklearn provides to help us build simple machine learning pipelines. We will also perform a simple machine learning experiment on a simple dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-Testing Set\n",
    "\n",
    "Recall that in the training-training set methodology, we simply split the dataset into two (unequally) sized blocks - a training set and a testing set. \n",
    "\n",
    "The training set is used to derive the model and its paramaters, and the testing set is then used to assess the quality of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split our data into a training set and a testing set\n",
    "# We want 20% of our data to be used for testing and the rest for training\n",
    "X_train, X_test, y_train, y_test = selection.train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate blank models\n",
    "lr_model = linear.LogisticRegression(solver='lbfgs', multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train models\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know we need to run predictions of the trained models on the testing set to get a sense of how well the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr_model.predict(X_test) # get predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-micro score of LR is  1.0\n",
      "F1-macro score of LR is  1.0\n"
     ]
    }
   ],
   "source": [
    "print('F1-micro score of LR is ', metrics.f1_score(y_test, pred_lr, average='micro'))\n",
    "print('F1-macro score of LR is ', metrics.f1_score(y_test, pred_lr, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of LR is\n",
      "[[ 6  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix of LR is')\n",
    "print(metrics.confusion_matrix(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have just lucked out with our split, let's run a k-fold with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = selection.StratifiedKFold(n_splits=5) # We used Stratified KFold since we have multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inzamamrahaman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/inzamamrahaman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/inzamamrahaman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/inzamamrahaman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/inzamamrahaman/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "f1_micro = []\n",
    "f1_macro= []\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lr = linear.LogisticRegression(multi_class='auto', solver='saga')\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions = lr.predict(X_test)\n",
    "    f1_micro.append(metrics.f1_score(y_test, predictions, average='micro'))\n",
    "    f1_macro.append(metrics.f1_score(y_test, predictions, average='macro'))\n",
    "    \n",
    "f1_micro = np.array(f1_micro)\n",
    "f1_macro = np.array(f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average f1 micro is  0.9866666666666667  with std. dev  0.016329931618554516\n",
      "Average f1 macro is  0.9866332497911445  with std. dev  0.01637085876546819\n"
     ]
    }
   ],
   "source": [
    "print('Average f1 micro is ', np.mean(f1_micro), ' with std. dev ', np.std(f1_micro))\n",
    "print('Average f1 macro is ', np.mean(f1_macro), ' with std. dev ', np.std(f1_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
